{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QAGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZbTWlcNp2Dn",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 6: Write\n",
        "\n",
        "## Question-Answer Generator\n",
        "\n",
        "The goal of this notebook is to create a model which can generate question and answer pairs about a block of text. This project is based on the [`qgen-workshop` TensorFlow codebase](https://github.com/Maluuba/qgen-workshop). The model consists of two components:\n",
        "\n",
        "- An RNN which identifies possible question answers from a block of text.\n",
        "\n",
        "- An encoder-decoder network that generates possible questions that the answers identified by the former model could be for.\n",
        "\n",
        "An _encoder-decoder_ network is a type of RNN that outputs a new sequence from its input. Some applications of encoder-decoder networks include machine translation, question generation, and text summarization. An encoder-decoder model trains an encoder RNN to encode the input sequence into a vector input for the decoder RNN which outputs a novel sequence from the vector input.\n",
        "\n",
        "## Question-Answer Dataset\n",
        "\n",
        "### Set Up\n",
        "\n",
        "Below we download and preprocess the data for the model. The data we are using for this notebook is provided by the [Maluuba News QA GitHub repository](https://github.com/Maluuba/newsqa). We use the manual setup instructions with the relevant code below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6J2MkhrsRcs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a15d6043-90be-429d-95fe-237ccce39697"
      },
      "source": [
        "!git clone https://github.com/Maluuba/newsqa"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'newsqa'...\n",
            "remote: Enumerating objects: 13, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 132 (delta 4), reused 4 (delta 2), pack-reused 119\u001b[K\n",
            "Receiving objects: 100% (132/132), 610.20 KiB | 2.45 MiB/s, done.\n",
            "Resolving deltas: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQkI4Al_tPuF",
        "colab_type": "text"
      },
      "source": [
        "For legal reasons, you have to download the data yourself on [Microsoft's website](https://msropendata.com/datasets/939b1042-6402-4697-9c15-7a28de7e1321) and state what you are using the data for. To save myself the trouble of having to reupload the data each time we get a new Colab kernel, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuanHAf9txrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount drive.\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')\n",
        "base_dir = '/content/gdrive/My Drive/gdl_models/qa/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vik_Bn7ewtV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "def load_or_copy(filename):\n",
        "  \"\"\"Load a file from Drive or copy it locally into Drive.\"\"\"\n",
        "  drive_path = base_dir + filename\n",
        "  if os.path.isfile(drive_path):\n",
        "    print('File exists in drive')\n",
        "    subprocess.call(['cp', drive_path, '.'])\n",
        "  else:\n",
        "    print('File exists locally')\n",
        "    subprocess.call(['cp', filename, drive_path])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odMLD1-5iOhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11740cf7-ac8a-40e0-d541-edc73454b2cc"
      },
      "source": [
        "load_or_copy('newsqa.tar.gz')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File exists in drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEaDd-xeifBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv newsqa.tar.gz newsqa/maluuba/newsqa/newsqa.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eZQIuS1z5am",
        "colab_type": "text"
      },
      "source": [
        "Now we also download the CNN stories we will use to train the model. You can download the stories [here](https://cs.nyu.edu/~kcho/DMQA/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEu_ZT0GjfpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "625c3b7c-15de-4c3d-d962-90471d672fc7"
      },
      "source": [
        "load_or_copy('cnn_stories.tgz')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File exists in drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U-0iyWOkrbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv cnn_stories.tgz newsqa/maluuba/newsqa/cnn_stories.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g59dHsLC39-b",
        "colab_type": "text"
      },
      "source": [
        "Now we upload the Java dependencies which can be found [here](https://nlp.stanford.edu/software/stanford-postagger-2015-12-09.zip)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImAW_vR84MBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d38d3fd-6890-4836-b93a-8e923fc9fcc9"
      },
      "source": [
        "load_or_copy('stanford-postagger-2015-12-09.zip')"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File exists in drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G-nUqCN-wP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r stanford-postagger-2015-12-09.zip newsqa/maluuba/newsqa/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Cylm1voVWf",
        "colab_type": "text"
      },
      "source": [
        "Now we run the data processing script in the repository. We run the repository's tests to make sure the data was processed correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RGUzWN0td9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd newsqa && python2 maluuba/newsqa/data_generator.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx-gzrvN1kyt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "d8f808b4-4e03-4ee1-e928-8b8496cdeb11"
      },
      "source": [
        "!cd newsqa && python2 -m unittest discover ."
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] 2020-05-04 00:25:51,936 - data_processing.py::__init__\n",
            "Loading dataset from `/content/newsqa/maluuba/newsqa/newsqa-data-v1.csv`...\n",
            "[INFO] 2020-05-04 00:25:51,936 - data_processing.py::load_combined\n",
            "Loading data from `/content/newsqa/maluuba/newsqa/newsqa-data-v1.csv`...\n",
            "[INFO] 2020-05-04 00:25:52,456 - data_processing.py::__init__\n",
            "Loading stories from `/content/newsqa/maluuba/newsqa/cnn_stories.tgz`...\n",
            "Getting story texts: 100% 12.7k/12.7k [00:12<00:00, 1.05k stories/s] \n",
            "Setting story texts: 100% 120k/120k [00:03<00:00, 37.0k questions/s] \n",
            "[INFO] 2020-05-04 00:26:07,792 - data_processing.py::__init__\n",
            "Done loading dataset.\n",
            "Checking for possible corruption: 100% 120k/120k [00:01<00:00, 103k questions/s]\n",
            ".[INFO] 2020-05-04 00:26:09,045 - data_processing.py::dump\n",
            "Packaging dataset to `/content/newsqa/combined-newsqa-data-v1.json`.\n",
            "Building json: 100% 120k/120k [00:05<00:00, 21.7k questions/s] \n",
            "Checking for possible corruption: 100% 12.7k/12.7k [00:00<00:00, 18.7k stories/s]\n",
            "Gathering answers: 100% 120k/120k [00:01<00:00, 107k questions/s]\n",
            "..[INFO] 2020-05-04 00:26:27,733 - data_processing.py::load_combined\n",
            "Loading data from `/content/newsqa/combined-newsqa-data-v1.csv`...\n",
            "Adjusting story texts: 100% 120k/120k [00:02<00:00, 58.6k questions/s]\n",
            "Comparing stories: 100% 120k/120k [00:30<00:00, 3.93k rows/s]\n",
            ".[INFO] 2020-05-04 00:27:03,871 - data_processing.py::load_combined\n",
            "Loading data from `/content/newsqa/maluuba/newsqa/newsqa-data-tokenized-v1.csv`...\n",
            "Adjusting story texts: 100% 120k/120k [00:02<00:00, 58.3k questions/s]\n",
            "....\n",
            "----------------------------------------------------------------------\n",
            "Ran 12 tests in 78.046s\n",
            "\n",
            "OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqIW19KgZLZ-",
        "colab_type": "text"
      },
      "source": [
        "Now let's save the data to Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5vEtQw8Fp9L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upload_to_drive(filepath):\n",
        "  \"\"\"Copy a file to Drive.\"\"\"\n",
        "  drive_path = base_dir + filepath.split('/')[-1]\n",
        "  subprocess.call(['cp', filepath, drive_path])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x__nql9IZeoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_to_drive('newsqa/split_data/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfDRjztAZrnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_to_drive('newsqa/split_data/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG3h7uLBZu6X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_to_drive('newsqa/split_data/dev.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}