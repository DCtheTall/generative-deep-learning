{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MuseGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aABRGKeFs1Qg",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 7: Compose\n",
        "\n",
        "## MuseGAN\n",
        "\n",
        "_MuseGAN_ is a generative machine learning model capable of generating new samples of _multiphonic_ music, i.e. it is capable of composing music with multiple tracks. This is in contrast to the LSTM with an attension mechanism in `AttentionMechanism.ipynb`, which can only generate _monophonic_ music.\n",
        "\n",
        "MuseGAN, which was introduced in [this paper](https://arxiv.org/abs/1709.06298), like other GANs, consists of a pair of convolutional neural networks, a generator and a critic. The MuseGAN we are building will be generating two new bars of choral music, using music composed by Bach for training.\n",
        "\n",
        "### MuseGAN Generator\n",
        "\n",
        "### MuseGAN Critic\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "### Downloading the Data\n",
        "\n",
        "Here I download the training data from a [this GitHub repository](https://github.com/czhuang/JSB-Chorales-dataset). For this repository I will use a fork of the repository at the time that I am writing this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3snFlKcsv_JQ",
        "colab_type": "code",
        "outputId": "ae4d01fb-f354-4b48-b688-3cdf0591359e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/DCtheTall/JSB-Chorales-dataset"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'JSB-Chorales-dataset'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Total 36 (delta 0), reused 0 (delta 0), pack-reused 36\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I4YqmDLjAUr",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing the Data\n",
        "\n",
        "The function below outputs the raw data, the data as a 4D tensor in the shape `[n_songs, n_bars, n_steps_per_bar, n_tracks]`. We then one hot encode the data into a 5D tensor of the shape `[n_songs, n_bars, n_steps_per_bar, n_notes, n_tracks]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2VDHx7Cxfhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_music(filename, n_bars, n_steps_per_bar):\n",
        "  \"\"\"Load the training data into memory and preprocess it.\"\"\"\n",
        "  with np.load(filename, encoding='bytes', allow_pickle=True) as f:\n",
        "    data = f['train']\n",
        "\n",
        "  data_ints = []\n",
        "  timesteps = n_bars * n_steps_per_bar\n",
        "  \n",
        "  for x in data:\n",
        "    counter = 0\n",
        "    while np.any(np.isnan(x[counter:(counter + 4)])):\n",
        "      counter += 4\n",
        "    if timesteps < x.shape[0]:\n",
        "      data_ints.append(x[counter:(counter + timesteps), :])\n",
        "\n",
        "  data_ints = np.array(data_ints)\n",
        "  n_songs, _, n_tracks = data_ints.shape\n",
        "  \n",
        "  data_ints = data_ints.reshape((n_songs, n_bars, n_steps_per_bar, n_tracks))\n",
        "\n",
        "  max_note = 83\n",
        "  where_nans = np.isnan(data_ints)\n",
        "  data_ints[where_nans] = max_note + 1\n",
        "  max_note += 1\n",
        "\n",
        "  data_ints = data_ints.astype(np.int)\n",
        "  n_classes = max_note + 1\n",
        "\n",
        "  data_binary = np.eye(n_classes)[data_ints]  # One-hot encode the pitches\n",
        "  data_binary[data_binary == 0] = -1  # Replace 0s with -1s.\n",
        "  # Remove the index indicating the last possible pitch. For that pitch, we\n",
        "  # can just use a row of all -1's.\n",
        "  data_binary = np.delete(data_binary, max_note, -1)\n",
        "  data_binary = data_binary.transpose((0, 1, 2, 4, 3))\n",
        "\n",
        "  return np.squeeze(data_binary), data_ints, data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcWXjnHHHYYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_BARS = 2\n",
        "N_STEPS_PER_BAR = 16\n",
        "\n",
        "data_binary, data_ints, data = load_music(\n",
        "    'JSB-Chorales-dataset/Jsb16thSeparated.npz', N_BARS, N_STEPS_PER_BAR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0S4dPVYU1c7",
        "colab_type": "text"
      },
      "source": [
        "### Playing the Training Data Music\n",
        "\n",
        "Let's play some of the training music to get a sense of the style the model is trying to learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSw0FS2QUglW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from music21 import stream, tempo, note, duration\n",
        "import os\n",
        "\n",
        "\n",
        "def binarise_generator_output(output):\n",
        "  \"\"\"Output has the shape [batch_size, bars, steps, pitches, tracks].\"\"\"\n",
        "  return np.argmax(output, axis=3)\n",
        "\n",
        "\n",
        "def notes_to_midi(output, outdir):\n",
        "  \"\"\"Writes output with shape [batch_size, bars, steps, pitches, tracks] to a midi files.\"\"\"\n",
        "  batch_size, n_bars, n_steps, n_pitches, n_tracks = output.shape\n",
        "  for idx in range(batch_size):\n",
        "    max_pitches = binarise_generator_output(output)\n",
        "    midi_note_score = max_pitches[idx].reshape([n_bars * n_steps, n_tracks])\n",
        "    parts = stream.Stream()\n",
        "    for track in range(n_tracks):\n",
        "      last_x = int(midi_note_score[:,track][0])\n",
        "      s = stream.Part()\n",
        "      dur = 0.0\n",
        "\n",
        "      for i, x in enumerate(midi_note_score[:, track]):\n",
        "        x = int(x)\n",
        "        if (x != last_x or i % 4 == 0) and i > 0:\n",
        "          n = note.Note(last_x)\n",
        "          n.duration = duration.Duration(dur)\n",
        "          s.append(n)\n",
        "          dur = 0\n",
        "        last_x = x\n",
        "        dur += 0.25\n",
        "      \n",
        "      n = note.Note(last_x)\n",
        "      n.duration = duration.Duration(dur)\n",
        "      s.append(n)\n",
        "\n",
        "      parts.append(s)\n",
        "    parts.write('midi', fp=os.path.join(outdir, '{}.midi'.format(idx)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geOo-PcsZU2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "notes_to_midi(data_binary[:3], '.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1_OZepuaaKo",
        "colab_type": "text"
      },
      "source": [
        "Convert the music into a .wav file using FluidSynth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH5q4qLsaKP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install fluidsynth\n",
        "!cp /usr/share/sounds/sf2/FluidR3_GM.sf2 ./font.sf2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ7zIBR0a6GH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0eca93c7-4b84-47e1-a68e-9b389b912427"
      },
      "source": [
        "!fluidsynth -ni font.sf2 0.midi -F 0.wav -r 1000"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FluidSynth version 1.1.9\n",
            "Copyright (C) 2000-2018 Peter Hanappe and others.\n",
            "Distributed under the LGPL license.\n",
            "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
            "\n",
            "Rendering audio to file '0.wav'..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljJ_JSUebGwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "65c707d0-e849-4817-afac-b524aca7b0e4"
      },
      "source": [
        "!fluidsynth -ni font.sf2 1.midi -F 1.wav -r 1000"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FluidSynth version 1.1.9\n",
            "Copyright (C) 2000-2018 Peter Hanappe and others.\n",
            "Distributed under the LGPL license.\n",
            "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
            "\n",
            "Rendering audio to file '1.wav'..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRvKUp-ybKfw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a5a75a0a-d1fa-47b7-81c8-2eb0701df08b"
      },
      "source": [
        "!fluidsynth -ni font.sf2 2.midi -F 2.wav -r 1000"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FluidSynth version 1.1.9\n",
            "Copyright (C) 2000-2018 Peter Hanappe and others.\n",
            "Distributed under the LGPL license.\n",
            "SoundFont(R) is a registered trademark of E-mu Systems, Inc.\n",
            "\n",
            "Rendering audio to file '2.wav'..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn4eQrOwbCc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Audio\n",
        "from scipy.io import wavfile\n",
        "\n",
        "rate, data = wavfile.read('0.wav')\n",
        "Audio(data.T, rate=rate, autoplay=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OK5M0m0dbM4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rate, data = wavfile.read('1.wav')\n",
        "Audio(data.T, rate=rate, autoplay=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdWf9F8ObQ0i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rate, data = wavfile.read('2.wav')\n",
        "Audio(data.T, rate=rate, autoplay=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZgCs_P4p1C3",
        "colab_type": "text"
      },
      "source": [
        "## Implementing MuseGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhvqOhiep01y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from tensorflow.keras.layers import (Input, Conv2DTranspose, BatchNormalization,\n",
        "                                     Activation, LeakyReLU, Reshape, Lambda,\n",
        "                                     Dense, Concatenate)\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "\n",
        "\n",
        "def conv_t(x, filters, kernel_size, strides, padding,\n",
        "           kernel_initializer='uniform_glorot', batch_norm_momentum=None,\n",
        "           activation='relu'):\n",
        "  \"\"\"Returns a convolutional transpose layer.\"\"\"\n",
        "  x = Conv2DTranspose(filters=filters, kernel_size=kernel_size, strides=strides,\n",
        "                      padding=padding, kernel_initializer=kernel_initializer)(x)\n",
        "  if batch_norm_momentum:\n",
        "    x = BatchNormalization(momentum=batch_norm_momentum)(x)\n",
        "  return LeakyReLU()(x) if activation == 'lrelu' else Activation(activation)(x)\n",
        "\n",
        "\n",
        "def TemporalNetwork(z_dim, n_bars, kernel_initializer, name):\n",
        "  \"\"\"Build a Temporal Network which generates n_bars vectors of shape z_dim.\"\"\"\n",
        "  input_layer = Input(shape=(z_dim,))\n",
        "  x = Reshape([1, 1, z_dim])(input_layer)\n",
        "  x = conv_t(x, filters=1024, kernel_size=(2, 1), strides=(1, 1),\n",
        "             activation='relu', batch_norm_momentum=0.9, padding='valid',\n",
        "             kernel_initializer=kernel_initializer)\n",
        "  x = conv_t(x, filters=z_dim, kernel_size=(n_bars - 1, 1), strides=(1, 1),\n",
        "             activation='relu', batch_norm_momentum=0.9, padding='valid',\n",
        "             kernel_initializer=kernel_initializer)\n",
        "  output_layer = Reshape([n_bars, z_dim])(x)\n",
        "  return Model(input_layer, output_layer, name=name)\n",
        "\n",
        "\n",
        "def BarGenerator(z_dim, n_steps_per_bar, n_pitches, kernel_initializer):\n",
        "  \"\"\"Bar Generator expands the time and pitch dimensions of the input.\"\"\"\n",
        "  input_layer = Input(shape=(4 * z_dim,))\n",
        "  x = Dense(1024)(input_layer)\n",
        "  x = BatchNormalization(momentum=0.9)(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Reshape([2, 1, 512])(x)\n",
        "  x = conv_t(x, filters=512, kernel_size=(2, 1), strides=(2, 1), padding='same',\n",
        "             activation='relu', batch_norm_momentum=0.9,\n",
        "             kernel_initializer=kernel_initializer)\n",
        "  x = conv_t(x, filters=256, kernel_size=(2, 1), strides=(2, 1), padding='same',\n",
        "             activation='relu', batch_norm_momentum=0.9,\n",
        "             kernel_initializer=kernel_initializer)\n",
        "  x = conv_t(x, filters=256, kernel_size=(2, 1), strides=(2, 1), padding='same',\n",
        "             activation='relu', batch_norm_momentum=0.9,\n",
        "             kernel_initializer=kernel_initializer)\n",
        "  x = conv_t(x, filters=256, kernel_size=(1, 7), strides=(1, 7), padding='same',\n",
        "             activation='relu', batch_norm_momentum=0.9,\n",
        "             kernel_initializer=kernel_initializer)\n",
        "  x = conv_t(x, filters=1, kernel_size=(1, 12), strides=(1, 12),\n",
        "             padding='same', activation='relu',\n",
        "             kernel_initializer=kernel_initializer)\n",
        "  output_layer = Reshape([1, n_steps_per_bar, n_pitches, 1])(x)\n",
        "  return Model(input_layer, output_layer)\n",
        "\n",
        "\n",
        "class MuseGAN(object):\n",
        "  \"\"\"Implementation of MuseGAN with Keras and TensorFlow.\"\"\"\n",
        "\n",
        "  def __init__(self, z_dim, n_tracks, n_bars, n_steps_per_bar, n_pitches):\n",
        "    chords_input = Input(shape=(z_dim,), name='chords_input')\n",
        "    style_input = Input(shape=(z_dim,), name='style_input')\n",
        "    melody_input = Input(shape=(n_tracks, z_dim), name='melody_input')\n",
        "    groove_input = Input(shape=(n_tracks, z_dim), name='groove_input')\n",
        "\n",
        "    weight_init = RandomNormal(mean=0.0, stddev=0.02)\n",
        "    self.chords_temp_network = TemporalNetwork(z_dim, n_bars, weight_init,\n",
        "                                               'temporal_network')\n",
        "    # Ouput shape is [?, n_bars, z_dim]\n",
        "    chords_output = self.chords_temp_network(chords_input)\n",
        "\n",
        "    melody_temp_networks = [None] * n_tracks\n",
        "    # Output shape will be [n_tracks, ?, n_bars, z_dim]\n",
        "    melody_outputs = [None] * n_tracks\n",
        "    for track in range(n_tracks):\n",
        "      melody_temp_networks[track] = TemporalNetwork(z_dim, n_bars, weight_init,\n",
        "                                                    'melody_{}'.format(track))\n",
        "      temp_network_input = Lambda(lambda x: x[:, track, :])(melody_input)\n",
        "      melody_outputs[track] = melody_temp_networks[track](temp_network_input)\n",
        "\n",
        "    self.bar_gen = [None] * n_tracks\n",
        "    for track in range(n_tracks):\n",
        "      self.bar_gen[track] = BarGenerator(z_dim, n_steps_per_bar, n_pitches,\n",
        "                                        weight_init)\n",
        "    \n",
        "    # Output shape will be [n_bars, ?, 1, n_steps_per_bar, n_pitches, n_tracks]\n",
        "    bars_output = [None] * n_bars\n",
        "    for bar in range(n_bars):\n",
        "      track_output = [None] * n_tracks\n",
        "      c = Lambda(lambda x: x[:, bar, :])(chords_output)\n",
        "      s = style_input\n",
        "      for track in range(n_tracks):\n",
        "        m = Lambda(lambda x: x[:, bar, :])(melody_outputs[track])\n",
        "        g = Lambda(lambda x: x[:, track, :])(groove_input)\n",
        "        z_input = Concatenate(axis=1)([c, s, m, g])\n",
        "        track_output[track] = self.bar_gen[track](z_input)\n",
        "      bars_output[bar] = Concatenate(axis=-1)(track_output)\n",
        "    \n",
        "    generator_output = Concatenate(axis=1)(bars_output)\n",
        "    self.generator = Model(\n",
        "        [chords_input, style_input, melody_input, groove_input],\n",
        "        generator_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QsGwszeq4KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z_DIM = 32\n",
        "N_TRACKS = 4\n",
        "N_PITCHES = 84\n",
        "\n",
        "gan = MuseGAN(z_dim=Z_DIM, \n",
        "              n_tracks=N_TRACKS,\n",
        "              n_bars=N_BARS,\n",
        "              n_steps_per_bar=N_STEPS_PER_BAR,\n",
        "              n_pitches=N_PITCHES)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}