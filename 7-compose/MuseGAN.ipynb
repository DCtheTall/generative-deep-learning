{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MuseGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aABRGKeFs1Qg",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 7: Compose\n",
        "\n",
        "## MuseGAN\n",
        "\n",
        "_MuseGAN_ is a generative machine learning model capable of generating new samples of _multiphonic_ music, i.e. it is capable of composing music with multiple tracks. This is in contrast to the LSTM with an attension mechanism in `AttentionMechanism.ipynb`, which can only generate _monophonic_ music.\n",
        "\n",
        "MuseGAN, which was introduced in [this paper](https://arxiv.org/abs/1709.06298), like other GANs, consists of a pair of convolutional neural networks, a generator and a critic. The MuseGAN we are building will be generating two new bars of choral music, using music composed by Bach for training.\n",
        "\n",
        "## Data Preparation\n",
        "\n",
        "### Downloading the Data\n",
        "\n",
        "Here I download the training data from a [this GitHub repository](https://github.com/czhuang/JSB-Chorales-dataset). For this repository I will use a fork of the repository at the time that I am writing this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3snFlKcsv_JQ",
        "colab_type": "code",
        "outputId": "ab6566ae-1a85-4cc7-a3cc-497dee31695a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!git clone https://github.com/DCtheTall/JSB-Chorales-dataset"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'JSB-Chorales-dataset'...\n",
            "remote: Enumerating objects: 36, done.\u001b[K\n",
            "remote: Total 36 (delta 0), reused 0 (delta 0), pack-reused 36\u001b[K\n",
            "Unpacking objects: 100% (36/36), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I4YqmDLjAUr",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing the Data\n",
        "\n",
        "The function below outputs the raw data, the data as a 4D tensor in the shape `[n_songs, n_bars, n_steps_per_bar, n_tracks]`. We then one hot encode the data into a 5D tensor of the shape `[n_songs, n_bars, n_steps_per_bar, n_notes, n_tracks]`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2VDHx7Cxfhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_music(filename, n_bars, n_steps_per_bar):\n",
        "  \"\"\"Load the training data into memory and preprocess it.\"\"\"\n",
        "  with np.load(filename, encoding='bytes', allow_pickle=True) as f:\n",
        "    data = f['train']\n",
        "\n",
        "  data_ints = []\n",
        "  timesteps = n_bars * n_steps_per_bar\n",
        "  \n",
        "  for x in data:\n",
        "    counter = 0\n",
        "    while np.any(np.isnan(x[counter:(counter + 4)])):\n",
        "      counter += 4\n",
        "    if timesteps < x.shape[0]:\n",
        "      data_ints.append(x[counter:(counter + timesteps), :])\n",
        "\n",
        "  data_ints = np.array(data_ints)\n",
        "  n_songs, _, n_tracks = data_ints.shape\n",
        "  \n",
        "  data_ints = data_ints.reshape((n_songs, n_bars, n_steps_per_bar, n_tracks))\n",
        "\n",
        "  max_note = 83\n",
        "  where_nans = np.isnan(data_ints)\n",
        "  data_ints[where_nans] = max_note + 1\n",
        "  max_note += 1\n",
        "\n",
        "  data_ints = data_ints.astype(np.int)\n",
        "  n_classes = max_note + 1\n",
        "\n",
        "  data_binary = np.eye(n_classes)[data_ints]  # One-hot encode the pitches\n",
        "  data_binary[data_binary == 0] = -1  # Replace 0s with -1s.\n",
        "  # Remove the index indicating the last possible pitch. For that pitch, we\n",
        "  # can just use a row of all -1's.\n",
        "  data_binary = np.delete(data_binary, max_note, -1)\n",
        "  data_binary = data_binary.transpose((0, 1, 2, 4, 3))\n",
        "\n",
        "  return np.squeeze(data_binary), data_ints, data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcWXjnHHHYYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N_BARS = 2\n",
        "N_STEPS_PER_BAR = 16\n",
        "\n",
        "data_binary, data_ints, data = load_music(\n",
        "    'JSB-Chorales-dataset/Jsb16thSeparated.npz', N_BARS, N_STEPS_PER_BAR)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}