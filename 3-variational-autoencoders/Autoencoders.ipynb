{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoders.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c0I6ul-32lP",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 3: Variational Autoencoders\n",
        "\n",
        "An _autoencoder_ is an artificial neural network with two parts:\n",
        "\n",
        "- An _encoder_ network which finds a representation of high dimensional data in a lower dimensional, or _latent_, space.\n",
        "\n",
        "- A _decoder_ network which reconstruct samples of the original data from elements of the latent space.\n",
        "\n",
        "### Your First Autoencoder\n",
        "\n",
        "Below is an example of an autoencoder which uses convolutional layers for the encoder network and _convolutional transpose layers_ for the decoder. The model uses MSE for the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mGPrhqV8Pvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import (Input, Conv2D, LeakyReLU, Flatten, Dense,\n",
        "                                     Reshape, Conv2DTranspose, Activation)\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "class Autoencoder():\n",
        "  \"\"\"Implements an autoencoder in Keras with an API for using the model.\"\"\"\n",
        "\n",
        "  def __init__(self, input_dim, encoder_conv_filters, encoder_conv_kernel_size,\n",
        "               encoder_conv_strides, z_dim, decoder_conv_filters,\n",
        "               decoder_conv_kernel_size, decoder_conv_strides):\n",
        "    encoder_input = Input(input_dim, name='encoder_input')\n",
        "    x = encoder_input\n",
        "    for i in range(len(encoder_conv_filters)):\n",
        "      x = Conv2D(filters=encoder_conv_filters[i],\n",
        "                 kernel_size=encoder_conv_kernel_size[i],\n",
        "                 strides=encoder_conv_strides[i],\n",
        "                 padding='same', name='encoder_conv_{}'.format(i))(x)\n",
        "      x = LeakyReLU()(x)\n",
        "\n",
        "    shape_before_flattening = K.int_shape(x)[1:]\n",
        "    x = Flatten()(x)\n",
        "    encoder_output = Dense(z_dim)(x)\n",
        "    encoder = Model(encoder_input, encoder_output)\n",
        "\n",
        "    decoder_input = Input(shape=(z_dim,), name='decoder_input')\n",
        "    x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "    x = Reshape(shape_before_flattening)(x)\n",
        "    for i in range(len(decoder_conv_filters)):\n",
        "      x = Conv2DTranspose(filters=decoder_conv_filters[i],\n",
        "                          kernel_size=decoder_conv_kernel_size[i],\n",
        "                          strides=decoder_conv_strides[i],\n",
        "                          padding='same', name='decoder_conv_{}'.format(i))(x)\n",
        "      if i < len(decoder_conv_filters) - 1:\n",
        "        x = LeakyReLU()(x)\n",
        "      else:\n",
        "        x = Activation('sigmoid')(x)\n",
        "    decoder_output = x\n",
        "    decoder = Model(decoder_input, decoder_output)\n",
        "    # Joining the models.\n",
        "    self.model = Model(encoder_input, decoder(encoder_output))\n",
        "\n",
        "    self.compiled = False\n",
        "\n",
        "  def compile(self, learning_rate):\n",
        "    \"\"\"Compile the model.\"\"\"\n",
        "    if self.compiled:\n",
        "      return\n",
        "    opt = Adam(lr=learning_rate)\n",
        "    mse = lambda y_act, y_pred: K.mean(K.square(y_act - y_pred), axis=(1, 2, 3))\n",
        "    self.model.compile(opt, loss=mse)\n",
        "    self.compiled = True\n",
        "\n",
        "  def fit(self, X, y, batch_size, epochs):\n",
        "    \"\"\"Train the model.\"\"\"\n",
        "    self.model.fit(X, y, batch_size=batch_size, epochs=epochs, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6d6y781FP3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the MNIST dataset.\n",
        "\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWeZlFq4G6jD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape these to be 4D tensors and scale the pixel values to [0, 1].\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape + (1,)) / 255.0\n",
        "X_test = X_test.reshape(X_test.shape + (1,)) / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7BckOvlGxxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "f5885dd7-9b09-4639-f3eb-c938c74715a2"
      },
      "source": [
        "autoencoder = Autoencoder(input_dim=X_train.shape[1:],\n",
        "                          encoder_conv_filters=(32, 64, 64, 64),\n",
        "                          encoder_conv_kernel_size=(3, 3, 3, 3),\n",
        "                          encoder_conv_strides=(1, 2, 2, 1),\n",
        "                          z_dim=2,\n",
        "                          decoder_conv_filters=(64, 64, 32, 1),\n",
        "                          decoder_conv_kernel_size=(3, 3, 3, 3),\n",
        "                          decoder_conv_strides=(1, 2, 2, 1))\n",
        "autoencoder.model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_0 (Conv2D)      (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_2 (Conv2D)      (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_3 (Conv2D)      (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 2)                 6274      \n",
            "_________________________________________________________________\n",
            "model_10 (Model)             (None, 28, 28, 1)         102017    \n",
            "=================================================================\n",
            "Total params: 200,963\n",
            "Trainable params: 200,963\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lyXPKsZOP8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO set up checkpoints in Drive and train for 200 epochs.\n",
        "\n",
        "autoencoder.compile(learning_rate=0.0005)\n",
        "autoencoder.fit(X_train, X_train, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCEnnZZSOHDw",
        "colab_type": "text"
      },
      "source": [
        "### Analysis of the Autoencoder\n",
        "\n",
        "TODO"
      ]
    }
  ]
}