{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WorldModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGTDL03VEWIP",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 8: Play\n",
        "\n",
        "This notebook contains an implementation of training an agent for the [OpenAI Gym `CarRacing-v0` environment](https://gym.openai.com/envs/CarRacing-v0/).\n",
        "\n",
        "## World Model\n",
        "\n",
        "This notebook will be using the [World Model architecture](https://arxiv.org/abs/1803.10122) to train a model for the `CarRacing-v0` environment using the model's own generated \"dream\" of the environment. The code is based on the implementation in [this repository](https://github.com/AppliedDataSciencePartners/WorldModels).\n",
        "\n",
        "The model is broken up into 3 main components: a variational autoencoder (VAE), a recurrent neural network with a mixture density network (MDN-RNN), and finally a controller.\n",
        "\n",
        "### The Variational Autoencoder\n",
        "\n",
        "The VAE will be trained first to encode the observations of different game states into a into a normally distributed, lower-dimensional latent space.\n",
        "\n",
        "### The MDN-RNN\n",
        "\n",
        "The MDN-RNN is trained after the VAE. Its goal is to predict the distribution of the next possible state in the latent space and the future reward at that state using the VAE's encoding, the most recent action, and the current reward as input. It consists of an LSTM network and a mixture-density network (MDN) output layer allows the next state could be sampled from numerous different normal distributions.\n",
        "\n",
        "### The Controller\n",
        "\n",
        "The controller is a densely connected neural network whose input is the concatenation of the output of the VAE and the hidden state of the LSTM network. The network's 3 output neurons represent the 3 possible actions the agent can take (steer, accelerate, brake).\n",
        "\n",
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V24D9sEgDUC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install Box2D gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPZ53O24EL77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zT6C9TpPENws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pyvirtualdisplay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl947KFAFHk7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive/')\n",
        "base_dir = '/content/gdrive/My Drive/gdl_models/world/'\n",
        "rollout_dir = os.path.join(base_dir, 'rollout/')\n",
        "vae_weights_dir = os.path.join(base_dir, 'vae/')\n",
        "series_dir = os.path.join(base_dir, 'series/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe0pn3RuLs84",
        "colab_type": "code",
        "outputId": "483693c2-f25a-4b7a-daa0-75f81c2de8be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(300, 300))\n",
        "display.start()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f50f8b7eb00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPKbsSO5EdON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z_DIM = 32\n",
        "ACTION_DIM = 3\n",
        "GAUSSIAN_MIXTURES = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8cGUQ4xaPuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "from tensorflow.keras.layers import (Input, Conv2D, BatchNormalization,\n",
        "                                     LeakyReLU, Dropout, Flatten, Dense,\n",
        "                                     Lambda, Reshape, Conv2DTranspose,\n",
        "                                     Activation, LSTM)\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLqiUG0xEljl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale_observation(obs):\n",
        "  \"\"\"Scale observation pixel values to [0, 1].\"\"\"\n",
        "  return obs.astype('float32') / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBZleHi4DWQ5",
        "colab_type": "text"
      },
      "source": [
        "## Generating the Rollout Data for the VAE\n",
        "\n",
        "Below is code that will generate the _rollout data_, data made up of observations of an agent acting randomly in the environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8R1sJPRPL7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_rollout_data(total_episodes=1000, timesteps=300,\n",
        "                         action_refresh_rate=20):\n",
        "  \"\"\"Collect the rollout data for training the VAE.\"\"\"\n",
        "  env = gym.make('CarRacing-v0')\n",
        "\n",
        "  for s in range(total_episodes):\n",
        "    print('Running episode:\\t', s)\n",
        "    episode_id = str(int(time.time()))\n",
        "    filename = os.path.join(rollout_dir, episode_id + '.npz')\n",
        "    obs = env.reset()\n",
        "    env.render()\n",
        "\n",
        "    observations = []\n",
        "    actions = []\n",
        "    rewards = []\n",
        "    done_sequence = []\n",
        "\n",
        "    reward = -0.1\n",
        "    done = False\n",
        "\n",
        "    for t in range(timesteps):\n",
        "      if t % action_refresh_rate == 0:\n",
        "        action = env.action_space.sample()\n",
        "      observations.append(scale_observation(obs))\n",
        "      actions.append(action)\n",
        "      rewards.append(reward)\n",
        "      done_sequence.append(done)\n",
        "\n",
        "      obs, reward, done, info = env.step(action)\n",
        "      env.render()\n",
        "\n",
        "    np.savez_compressed(filename, obs=observations, action=actions,\n",
        "                        reward=rewards, done=done_sequence)\n",
        "  env.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MIrjREPKc80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collect_rollout_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Q9g7HuPJy6",
        "colab_type": "text"
      },
      "source": [
        "## Implementing and Training the VAE\n",
        "\n",
        "Below we will implement the variational autoencoder (VAE) this model will use to encode the game state into a normal distribution in a lower-dimensional latent space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcmbpMw1P6sK",
        "colab_type": "code",
        "outputId": "72fcf4ae-01fe-4a08-c793-6158098efae4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def sampling(args):\n",
        "  \"\"\"Sample an encoding from the learned distribution.\"\"\"\n",
        "  mu, log_var = args\n",
        "  return mu + K.exp(log_var / 2) * K.random_normal(shape=K.shape(mu))\n",
        "\n",
        "\n",
        "def step_decay_schedule(initial_lr, decay_factor=0.5, step_size=1):\n",
        "  \"\"\"Create a LearningRateScheduler callback to decay the learning rate during training.\"\"\"\n",
        "  def schedule(epoch):\n",
        "    return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
        "  return LearningRateScheduler(schedule)\n",
        "\n",
        "\n",
        "class VAE():\n",
        "  \"\"\"Implements a varational autoencoder (VAE) using Keras.\"\"\"\n",
        "\n",
        "  def __init__(self, input_shape, encoder_conv_filters,\n",
        "               encoder_conv_kernel_size, encoder_conv_strides,\n",
        "               encoder_activations, decoder_conv_filters,\n",
        "               decoder_conv_kernel_size, decoder_conv_strides,\n",
        "               decoder_activations, z_dim, use_batch_normalization=False,\n",
        "               use_dropout=False, dropout_rate=0.25):\n",
        "    encoder_input = Input(shape=input_shape, name='encoder_input')\n",
        "    x = encoder_input\n",
        "    for i in range(len(encoder_conv_kernel_size)):\n",
        "      x = Conv2D(filters=encoder_conv_filters[i],\n",
        "                 kernel_size=encoder_conv_kernel_size[i],\n",
        "                 strides=encoder_conv_strides[i], padding='same',\n",
        "                 name='encoder_conv_{}'.format(i + 1))(x)\n",
        "      if use_batch_normalization:\n",
        "        x = BatchNormalization()(x)\n",
        "      if encoder_activations[i] == 'lrelu':\n",
        "        x = LeakyReLU()(x)\n",
        "      else:\n",
        "        x = Activation(encoder_activations[i])(x)\n",
        "      if use_dropout:\n",
        "        x = Dropout(rate=dropout_rate)(x)\n",
        "    shape_before_flattening = K.int_shape(x)[1:]\n",
        "    x = Flatten()(x)\n",
        "    self.z_dim = z_dim\n",
        "    self.mu = Dense(z_dim, name='mu')(x)\n",
        "    self.log_var = Dense(z_dim, name='log_var')(x)\n",
        "    self.encoder_mu_log_var = Model(encoder_input, (self.mu, self.log_var))\n",
        "    encoder_output = Lambda(sampling,\n",
        "                            name='encoder_output')([self.mu, self.log_var])\n",
        "    self.encoder = Model(encoder_input, encoder_output)\n",
        "\n",
        "    decoder_input = Input(shape=(z_dim,), name='decoder_input')\n",
        "    x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "    x = Reshape(shape_before_flattening)(x)\n",
        "    for i in range(len(decoder_conv_kernel_size)):\n",
        "      x = Conv2DTranspose(filters=decoder_conv_filters[i],\n",
        "                          kernel_size=decoder_conv_kernel_size[i],\n",
        "                          strides=decoder_conv_strides[i], padding='same',\n",
        "                          name='decoder_conv_t_{}'.format(i + 1))(x)\n",
        "      if i < len(decoder_conv_kernel_size) - 1:\n",
        "        if use_batch_normalization:\n",
        "          x = BatchNormalization()(x)\n",
        "      if decoder_activations[i] == 'lrelu':\n",
        "        x = LeakyReLU()(x)\n",
        "      else:\n",
        "        x = Activation(decoder_activations[i])(x)\n",
        "      if use_dropout and i < len(decoder_conv_kernel_size) - 1:\n",
        "          x = Dropout(rate=dropout_rate)(x)\n",
        "    decoder_output = x\n",
        "    self.decoder = Model(decoder_input, decoder_output)\n",
        "    self.model = Model(encoder_input, self.decoder(encoder_output))\n",
        "    self.compiled = False\n",
        "    self.learning_rate = None\n",
        "\n",
        "  def compile(self, learning_rate, r_loss_factor):\n",
        "    \"\"\"Compile the model.\"\"\"\n",
        "    self.learning_rate = learning_rate\n",
        "    if self.compiled:\n",
        "      return\n",
        "    opt = Adam(lr=learning_rate)\n",
        "\n",
        "    def mse(y_act, y_pred):\n",
        "      return r_loss_factor * K.mean(K.square(y_act - y_pred), axis=(1, 2, 3))\n",
        "\n",
        "    def kl_divergence(y_act, y_pred):\n",
        "      return -0.5 * K.sum(\n",
        "        1 + self.log_var - K.square(self.mu) - K.exp(self.log_var), axis=1)\n",
        "\n",
        "    def loss(y_act, y_pred):\n",
        "      return mse(y_act, y_pred) + kl_divergence(y_act, y_pred)\n",
        "    \n",
        "    self.model.compile(opt, loss=loss, metrics=[mse, kl_divergence],\n",
        "                       experimental_run_tf_function=False)\n",
        "    self.compiled = True\n",
        "\n",
        "  def fit_with_generator(self, data_flow, epochs, steps_per_epoch,\n",
        "                         checkpoint_path=None, lr_decay=1, initial_epoch=0,):\n",
        "    if not self.compiled:\n",
        "      raise Exception('Model not compiled')\n",
        "    if initial_epoch > 0:\n",
        "      self.load(checkpoint_path + 'weights_{:03d}.hdf5'.format(initial_epoch))\n",
        "    lr_sched = step_decay_schedule(initial_lr=self.learning_rate,\n",
        "                                   decay_factor=lr_decay, step_size=1)\n",
        "    callbacks = [lr_sched]\n",
        "    if checkpoint_path:\n",
        "      callbacks.append(ModelCheckpoint(\n",
        "          filepath=checkpoint_path + 'weights.hdf5', verbose=1,\n",
        "          save_weights_only=True))\n",
        "      callbacks.append(ModelCheckpoint(\n",
        "          filepath=checkpoint_path + 'weights_{epoch:03d}.hdf5', verbose=1,\n",
        "          save_weights_only=True))\n",
        "    self.model.fit_generator(data_flow, epochs=epochs, shuffle=True,\n",
        "                             callbacks=callbacks, initial_epoch=initial_epoch,\n",
        "                             steps_per_epoch=steps_per_epoch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8khl43JDjzjV",
        "colab_type": "text"
      },
      "source": [
        "I will initialize the model with mostly the same hyperparameters are the [original code](https://github.com/AppliedDataSciencePartners/WorldModels/blob/master/vae/arch.py), but with some modifications to see how they impact the performance of the overall model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhEw77JbjyRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "vae = VAE(input_shape=(96, 96, 3),\n",
        "          encoder_conv_filters=(32, 64, 64, 128),\n",
        "          encoder_conv_kernel_size=(4, 4, 4, 4),\n",
        "          encoder_conv_strides=(2, 2, 2, 2),\n",
        "          encoder_activations=('relu', 'relu', 'relu', 'relu'),\n",
        "          decoder_conv_filters=(64, 64, 32, 3),\n",
        "          decoder_conv_kernel_size=(5, 5, 6, 6),\n",
        "          decoder_conv_strides=(2, 2, 2, 2),\n",
        "          decoder_activations=('relu', 'relu', 'relu', 'sigmoid'),\n",
        "          z_dim=Z_DIM)\n",
        "vae.compile(LEARNING_RATE, r_loss_factor=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drpFtUCIRq9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae.model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMRGQIZ2F9ol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 100\n",
        "EPOCHS = 10\n",
        "N_IMGS = 300 * len(os.listdir(rollout_dir))\n",
        "STEPS_PER_EPOCH = N_IMGS // BATCH_SIZE\n",
        "N_LOADS_PER_BATCH = 300 // BATCH_SIZE\n",
        "IMAGE_SIZE = (96, 96)\n",
        "\n",
        "def vae_training_data():\n",
        "  \"\"\"Load the VAE training data.\"\"\"\n",
        "  fnames = os.listdir(rollout_dir)\n",
        "  fnames.sort()\n",
        "  while True:\n",
        "    for fname in fnames:\n",
        "      new_data = np.load(rollout_dir + fname)['obs']\n",
        "      data = np.zeros((BATCH_SIZE, *IMAGE_SIZE, 3))\n",
        "      for i in range(N_LOADS_PER_BATCH):\n",
        "        data[:,:,:,:] = new_data[i * BATCH_SIZE:(i + 1) * BATCH_SIZE, :, :, :]\n",
        "        yield data, data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgZnfIQIHoRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = vae_training_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw4Ag6n5KUvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae.fit_with_generator(X_train, epochs=EPOCHS,\n",
        "                       steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                       checkpoint_path=vae_weights_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3JeL13ahjsN",
        "colab_type": "text"
      },
      "source": [
        "### Analyzing the VAE\n",
        "\n",
        "First we will analyze how the VAE reconstructs images from the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj8wXVk3hlIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vae.model.load_weights(vae_weights_dir + 'weights.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJmMd2mKhsBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = vae_training_data()\n",
        "next(X_train)\n",
        "next(X_train)\n",
        "batch, _ = next(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-Ku7eWGh1Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = batch[90]\n",
        "plt.imshow(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAgrIDrliDwe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = vae.model.predict([[x]])[0]\n",
        "plt.imshow(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hquw7U_xY36O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mu, log_var = vae.encoder_mu_log_var.predict([[x]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xx_ZB7gY_b9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mu = mu.reshape((32,))\n",
        "log_var = log_var.reshape((32,))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlzau28lZm9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(np.arange(0, 32), mu, np.arange(0, 32), log_var)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89fsx7HDjSAH",
        "colab_type": "text"
      },
      "source": [
        "Another way to test the performance of an autonecoder is to decode randomly sampled noise from the latent space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prszRgLFjJL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = plt.imshow(\n",
        "    vae.decoder.predict(np.random.normal(0.0, 1.0, size=(1, Z_DIM)))[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo3d6SfzZ8ov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = plt.imshow(\n",
        "    vae.decoder.predict(np.random.normal(-2.0, 1.0, size=(1, Z_DIM)))[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQG4jUsDaHz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = plt.imshow(\n",
        "    vae.decoder.predict(np.random.normal(2.0, 1.0, size=(1, Z_DIM)))[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkJ_pc8IXrXO",
        "colab_type": "text"
      },
      "source": [
        "## Collecting Rollout Data for the MDN-RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wv80z1djqAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collect_rnn_series_data():\n",
        "  \"\"\"Collect training data for the MDN-RNN.\"\"\"\n",
        "  fnames = os.listdir(rollout_dir)\n",
        "  fnames.sort()\n",
        "  initial_mus = []\n",
        "  initial_log_vars = []\n",
        "  for fname in fnames:\n",
        "    episode = np.load(os.path.join(rollout_dir, fname))\n",
        "    obs = episode['obs']\n",
        "    action = episode['action']\n",
        "    reward = episode['reward']\n",
        "    done = episode['done']\n",
        "\n",
        "    done = done.astype(int)\n",
        "    reward = np.where(reward > 0, 0.0, 1.0) * np.where(done == 0, 1, 0)\n",
        "    \n",
        "    mu, log_var = vae.encoder_mu_log_var.predict(obs)\n",
        "\n",
        "    np.savez_compressed(os.path.join(series_dir, fname), mu=mu,\n",
        "                        log_var=log_var, action=action, reward=reward,\n",
        "                        done=done)\n",
        "    \n",
        "    initial_mus.append(mu[0, :])\n",
        "    initial_log_vars.append(log_var[0, :])\n",
        "  np.savez_compressed(os.path.join(base_dir, 'initial_z.npz'),\n",
        "                      initial_mus=initial_mus,\n",
        "                      initial_log_vars=initial_log_vars)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKFA3CIZxFSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "collect_rnn_series_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwDyux2QQUz5",
        "colab_type": "text"
      },
      "source": [
        "## The MDN-RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1X1zrrk0rdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_response(y_true):\n",
        "  \"\"\"Get actual game state and reward from training set.\"\"\"\n",
        "  z_true = y_true[:, :, :Z_DIM]\n",
        "  rew_true = y_true[:, :, -1]\n",
        "  return z_true, rew_true\n",
        "\n",
        "\n",
        "def get_mixture_coeff(z_pred):\n",
        "  \"\"\"Separate the predicted 480 dimensional state into 3 variables.\"\"\"\n",
        "  log_pi, mu, log_sigma = tf.split(z_pred, 3, 1)\n",
        "  # Axis 1 is the mixture coefficient.\n",
        "  log_pi = log_pi - K.log(K.sum(K.exp(log_pi), axis=1, keepdims=True))\n",
        "  return log_pi, mu, log_sigma\n",
        "\n",
        "\n",
        "def tf_lognormal(z_true, mu, log_sigma):\n",
        "  \"\"\"Compute sample from the log-normal distribution.\"\"\"\n",
        "  log_sqrt_2 = np.log(np.sqrt(2.0 * np.pi))\n",
        "  return -0.5 * ((z_true - mu) / K.exp(log_sigma)) ** 2 - log_sigma - log_sqrt_2\n",
        "\n",
        "\n",
        "def build_rnn_z_loss(guassian_mixtures, z_dim):\n",
        "  \"\"\"Compute the negative log-likelihood that z_true was sampled from the predicted distribution.\"\"\"\n",
        "  def compute_loss(y_true, y_pred):\n",
        "    z_true, _ = get_response(y_true)\n",
        "    d = guassian_mixtures * z_dim\n",
        "    z_pred = y_pred[:, :, :(3 * d)]\n",
        "    z_pred = K.reshape(z_pred, [-1, guassian_mixtures * 3])\n",
        "    log_pi, mu, log_sigma = get_mixture_coeff(z_pred)\n",
        "    flat_z_true = K.reshape(z_true, [-1, 1])\n",
        "    z_loss = log_pi + tf_lognormal(flat_z_true, mu, log_sigma)\n",
        "    z_loss = -K.log(K.sum(K.exp(z_loss), 1, keepdims=True))\n",
        "    return K.mean(z_loss)\n",
        "  return compute_loss\n",
        "\n",
        "\n",
        "def build_rnn_rew_loss(guassian_mixtures, z_dim):\n",
        "  \"\"\"Compute the reward loss.\"\"\"\n",
        "  def compute_loss(y_true, y_pred):\n",
        "    _, rew_true = get_response(y_true)\n",
        "    d = guassian_mixtures * z_dim\n",
        "    rew_pred = y_pred[:, :, -1]\n",
        "    rew_loss = K.binary_crossentropy(rew_true, rew_pred, from_logits=True)\n",
        "    return K.mean(rew_loss)\n",
        "  return compute_loss\n",
        "\n",
        "\n",
        "def build_rnn_loss(rnn_z_loss, rnn_rew_loss, z_factor, rew_factor):\n",
        "  \"\"\"Build the loss function.\"\"\"\n",
        "  def compute_loss(y_true, y_pred):\n",
        "    loss = z_factor * rnn_z_loss(y_true, y_pred)\n",
        "    loss += rew_factor * rnn_rew_loss(y_true, y_pred)\n",
        "    return loss\n",
        "  return compute_loss\n",
        "\n",
        "\n",
        "class MDNRNN(object):\n",
        "  \"\"\"MDN-RNN implementation.\"\"\"\n",
        "\n",
        "  def __init__(self, hidden_units=256, guassian_mixtures=GAUSSIAN_MIXTURES,\n",
        "               z_dim=Z_DIM, action_dim=ACTION_DIM, z_factor=1, reward_factor=1,\n",
        "               learning_rate=0.001):\n",
        "    # Shared layers.\n",
        "    model_in = Input(shape=(None, z_dim + action_dim + 1))\n",
        "    lstm = LSTM(hidden_units, return_sequences=True,\n",
        "                return_state=True)\n",
        "    mdn = Dense((3 * guassian_mixtures * z_dim) + 1)\n",
        "\n",
        "    # Model to be trained.\n",
        "    x, _, _ = lstm(model_in)\n",
        "    train_out = mdn(x)\n",
        "    self.model = Model(model_in, train_out)\n",
        "    \n",
        "    # Model for predictions.\n",
        "    state_input_h = Input(shape=(hidden_units,))\n",
        "    state_input_c = Input(shape=(hidden_units,))\n",
        "\n",
        "    x, state_h, state_c = lstm(model_in,\n",
        "                               initial_state=[state_input_h, state_input_c])\n",
        "    mdn_out = mdn(x)\n",
        "    self.forward_model = Model([model_in, state_input_h, state_input_c],\n",
        "                               [mdn_out, state_h, state_c])\n",
        "    \n",
        "    z_loss = build_rnn_z_loss(guassian_mixtures, z_dim)\n",
        "    rew_loss = build_rnn_rew_loss(guassian_mixtures, z_dim)\n",
        "    loss = build_rnn_loss(z_loss, rew_loss, z_factor, reward_factor)\n",
        "    \n",
        "    self.model.compile(optimizer=Adam(lr=learning_rate), loss=loss,\n",
        "                       metrics=[z_loss, rew_loss])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_lzyPmN8iYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e9b60414-b58d-4db7-a922-89ffdc754d26"
      },
      "source": [
        "rnn = MDNRNN()\n",
        "rnn.model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, None, 36)]        0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                [(None, None, 256), (None 300032    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, None, 481)         123617    \n",
            "=================================================================\n",
            "Total params: 423,649\n",
            "Trainable params: 423,649\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}